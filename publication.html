<tr>
    <td class="header" colspan="2">
        Publications
        <button class="pub-toggle-btn-global"></button>
    </td>
</tr>
<tr>
    <td colspan="2">
        <table class="table-contents">
            <tbody>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <img class="img-zoom" src="src/papers/imgs/3dsuperres.jpg" alt="3D Simulation Super-resolution">
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Near-realtime Facial Animation by Deep 3D Simulation
                            Super-resolution</span>
                        <span class="my-author">Hyojoon Park</span>, Sangeetha Grama Srinivasan, Matthew Cong, Doyub
                        Kim, Byungsoo Kim, Jonathan Swartz, Ken Museth, and Eftychios Sifakis
                        <br>
                        <span class="conference">ACM Transactions on Graphics (TOG) 2024</span>
                        <br>
                        <a href="https://dl.acm.org/doi/full/10.1145/3670687" target="_blank">paper</a>
                        |
                        <a href="https://github.com/hjoonpark/3d-sim-super-res" target="_blank">github</a>
                        |
                        presented at <a href="https://asia.siggraph.org/2024/full-program/" target="_blank">SIGGRAPH
                            ASIA 2024</a>
                        <br><button class="pub-toggle-btn"></button>
                    </td>
                </tr>
                <tr>
                    <td colspan="2">
                        <div class="pub-toggle-content">
                            <ul>
                                <li>3D simulation super-resolution achieving high-resolution facial animation 115x
                                    faster (at 18 FPS) than traditional method while maintaining similar quality.</li>
                                <li>Enhances low-resolution simulations to high-resolution surfaces while generalizing
                                    to unseen facial expressions, external forces, and dynamics.</li>
                            </ul>
                        </div>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <a href="https://youtu.be/Y2JJylfbuKM?si=BcbfbqSJ269NR7Jy" target="_blank" class="video-link">
                            <img src="https://img.youtube.com/vi/Y2JJylfbuKM/maxresdefault.jpg"
                                alt="YouTube Video Thumbnail" class="thumbnail"
                                onerror="this.onerror=null; this.src='https://img.youtube.com/vi/Y2JJylfbuKM/hqdefault.jpg';">
                            <i class="fa fa-play play-icon"></i>
                        </a>
                    </td>
                    <td class="tb-td-right">
                        Our work is featured on the &#128250; <a href="https://youtu.be/Y2JJylfbuKM?si=nF2flmEF39Omn-CC"
                            target="_blank">Two Minute Papers</a> channel!
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <img class="img-zoom" src="src/papers/imgs/media2022.jpg"
                            alt="Collagen Fiber Centerline Tracking">
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Collagen Fiber Centerline Tracking in Fibrotic Tissue via Deep Neural
                            Networks with Variational Autoencoder-based Synthetic Training Data Generation</span>
                        <span class="my-author">Hyojoon Park</span>*, Bin Li*, Yuming Liu, Michael S. Nelson, Helen M.
                        Wilson, Eftychios Sifakis, and Kevin W. Eliceiri. (* equal contributions)
                        <br>
                        <span class="conference">Medical Image Analysis 2023</span>
                        <br>
                        <a href="https://www.sciencedirect.com/science/article/pii/S1361841523002219"
                            target="_blank">paper</a>
                        |
                        <a href="https://github.com/uw-loci/collagen-fiber-metrics.git" target="_blank">github</a>
                        <br><button class="pub-toggle-btn"></button>
                    </td>
                </tr>
                <tr>
                    <td colspan="2">
                        <div class="pub-toggle-content">
                            <ul>
                                <li>Introduces a novel property-controllable variational autoencoder, DuoVAE, designed
                                    to generate synthetic data with desired properties.</li>
                                <li>Facilitates the creation of diverse synthetic datasets, addressing the challenge of
                                    limited annotated data for training deep learning models.</li>
                            </ul>
                        </div>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <img class="img-zoom" src="src/papers/imgs/tog21.JPG" alt="Capturing Detailed Deformations">
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Capturing Detailed Deformations of Moving Human Bodies</span>
                        He Chen, <span class="my-author">Hyojoon Park</span>, Kutay Macit, and Ladislav Kavan
                        <br>
                        <span class="conference">ACM SIGGRAPH 2021</span>
                        <br>
                        <a href="https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Capturing+Detailed+Deformations+of+Moving+Human+Bodies&btnG="
                            target="_blank">paper</a>
                        |
                        <a href="https://ankachan.github.io/Projects/MocapCheckerboard/MocapCheckerboard.html"
                            target="_blank">project page</a>
                        |
                        <a href="https://github.com/hjoonpark/MultiCamCalib" target="_blank">multi-camera calibration
                            codes</a>
                        <br><button class="pub-toggle-btn"></button>
                    </td>
                </tr>
                <tr>
                    <td colspan="2">
                        <div class="pub-toggle-content">
                            <ul>
                                <li>Introduces a novel motion capture system in a multi-camera setup using a specially
                                    designed low-cost suit, enabling the accurate 3D reconstruction of a moving human
                                    body.</li>
                                <li>Uses deep neural networks and geometric algorithms for accurate corner detection,
                                    labeling, and 3D reconstruction.</li>
                                <li>Developed and deployed the multi-camera calibration framework enhanced by machine
                                    learning-based anomaly corner detection.</li>
                            </ul>
                        </div>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <img class="img-zoom" src="src/papers/imgs/iros2020.jpg"
                            alt="Adaptive Precision-Enhancing Hand Rendering">
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Adaptive Precision-Enhancing Hand Rendering for Wearable Fingertip
                            Tracking Devices</span>
                        <span class="my-author">Hyojoon Park</span> and Jung-Min Park
                        <br>
                        <span class="conference">IEEE/RSJ International Conference on Intelligent Robots and Systems
                            (IROS) 2020</span>
                        <br>
                        <a href="https://scholar.google.com/scholar?hl=en&as_sdt=0%2C45&q=Adaptive+Precision-Enhancing+Hand+Rendering+for+Wearable+Fingertip+Tracking+Devices&btnG="
                            target="_blank">paper</a>
                        |
                        <a href="https://youtu.be/_JeicPxjsXQ" target="_blank">short video</a>
                        <br><button class="pub-toggle-btn"></button>
                    </td>
                </tr>
                <tr>
                    <td colspan="2">
                        <div class="pub-toggle-content">
                            <ul>
                                <li>Introduces 3D hand rendering framework in VR for wearable fingertip tracking
                                    devices, focusing on reconstructing realistic hand poses using only fingertip
                                    positions.</li>
                                <li>Key contributions include motion retargeting and new hinge constraints for real-time
                                    inverse kinematics to enhance visual plausibility and precision.</li>
                            </ul>
                        </div>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <img class="img-zoom" src="src/papers/imgs/dental.PNG" alt="Dental Simulator">
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Dental Simulator with Increased Z-width of Haptic Rendering</span>
                        <span class="my-author">Hyojoon Park</span>, Myungsin Kim, and Dongjun Lee
                        <br>
                        <span class="conference">AsiaHaptics 2018</span>
                        <br>
                        <a href="src/papers/ThesisContents.pdf" target="_blank">MS thesis</a>
                        |
                        <a href="src/papers/HPark_AsiaHaptics18_ShortPaper.pdf" target="_blank">short paper</a>
                        |
                        <a href="https://youtu.be/R7unVX3cIXg" target="_blank">short video</a>
                        |
                        <a href="src/papers/videos/master_degree_compressed.mp4" target="_blank">long video</a>[*]
                        <br><br>
                        [*] <span class="tooltip"><a href="src/papers/snu_outstanding_ms_thesis.jpeg">Outstanding MS
                                Thesis Presentation Award</a><span class="tooltiptext-image"><img
                                    src="src/papers/snu_outstanding_ms_thesis.jpeg"
                                    alt="Outstanding MS Thesis Presentation Award"></span></span> (Seoul National
                        University 2019)
                        <br><button class="pub-toggle-btn"></button>
                    </td>
                </tr>
                <tr>
                    <td colspan="2">
                        <div class="pub-toggle-content">
                            <ul>
                                <li>Introduces a VR dental simulator that renders highly stiff haptic feedback,
                                    achieving up to 10Ã— greater maximum stiffness (Z-width) from virtual teeth using
                                    commercially available haptic devices.</li>
                            </ul>
                        </div>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <img class="img-zoom" src="src/papers/imgs/glove.jpeg"
                            alt="Stretchable Skin-Like Cooling/Heating Device">
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Stretchable Skin-Like Cooling/Heating Device for Reconstruction of
                            Artificial Thermal Sensation in Virtual Reality</span>
                        Jnwoo Lee, Heayoun Sul, Wonha Lee, Kyung Rok Pyun, Inho Ha, Dongkwan Kim, <span
                            class="my-author">Hyojoon Park</span>, Hyeonjin Eom, Yeosang Yoon, Jinwook Jung, Dongjun
                        Lee, and Seung Hwan Ko
                        <br>
                        <span class="conference">Advanced Functional Materials 2020</span>
                        <br>
                        <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/adfm.201909171"
                            target="_blank">paper</a>
                        <br><button class="pub-toggle-btn"></button>
                    </td>
                </tr>
                <tr>
                    <td colspan="2">
                        <div class="pub-toggle-content">
                            <ul>
                                <li>Introduces a stretchable, bi-functional skin-like thermo-haptic (STH) device for VR,
                                    capable of precise cold and hot sensations with a single structure and 230%
                                    stretchability.</li>
                            </ul>
                        </div>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <img class="img-zoom" src="src/papers/imgs/highly_stretchable.jpeg"
                            alt="Highly Stretchable Cu Nanowire Heater">
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Highly Stretchable and Oxidation-resistive Cu Nanowire Heater for
                            Replication of the Feeling of Heat in a Virtual World</span>
                        Dongkwan Kim, Junhyuk Bang, Wonha Lee, Inho Ha, Jinwoo Lee, Hyeonjin Eom, Myungsin
                        Kim, Jungjae Park, Joonhwa Choi, Jinhyung Kwon, Seungyong Han, <span class="my-author">Hyojoon
                            Park</span>, Dongjun Lee, and Seung Hwan Ko
                        <br>
                        <span class="conference">Journal of Materials Chemistry A 2020</span>
                        <br>
                        <a href="https://pubs.rsc.org/en/content/articlelanding/2020/ta/d0ta00380h"
                            target="_blank">paper</a>
                        <br><button class="pub-toggle-btn"></button>
                    </td>
                </tr>
                <tr>
                    <td colspan="2">
                        <div class="pub-toggle-content">
                            <ul>
                                <li>Proposes laser-assisted dual-function copper nanowire (CuNW) polyurethane acrylate
                                    (PUA) patterns as feedback-controllable stretchable heaters for a 12-pixel thermal
                                    haptic device, with enhanced mechanical and chemical durability.</li>
                                <li>Demonstrates a stretchable thermal haptic device on a nylon glove that replicates
                                    heat transfer in various virtual environments, achieving temperature control with
                                    less than 5% error.</li>
                            </ul>
                        </div>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <img class="img-zoom" src="src/papers/imgs/collaborative.PNG"
                            alt="Rigid-body Collaborative Manipulation">
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Rigid-body Collaborative Manipulation among Remote Users with Wearable
                            Cutaneous Haptic Interfaces</span>
                        Myungsin Kim, WonHa Lee, <span class="my-author">Hyojoon Park</span>, Junghan Kwon, Yong-Lae
                        Park, and Dongjun Lee
                        <br>
                        <span class="conference">AsiaHaptics 2018</span>
                        <br>
                        <a href="src/papers/MKim_AsiaHaptics18.pdf" target="_blank">paper</a>
                        |
                        <a href="src/papers/videos/low_AsiaHaptics2018_KMS.mp4" target="_blank">video</a>
                        <br><button class="pub-toggle-btn"></button>
                    </td>
                </tr>
                <tr>
                    <td colspan="2">
                        <div class="pub-toggle-content">
                            <ul>
                                <li>Introduces a remote multiuser collaboration system via wearable cutaneous haptic
                                    interfaces, leveraging passivity-based simulations for stable and realistic
                                    interactions.</li>
                            </ul>
                        </div>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <div class="img-placeholder-with-logo">
                            <img src="src/logo/snu.png" alt="Seoul National University" class="placeholder-logo">
                        </div>
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Design and Performance Evaluation of Wearable Haptic Interfaces</span>
                        WonHa Lee, Myungsin Kim, <span class="my-author">Hyojoon Park</span>, and Dongjun Lee
                        <br>
                        <span class="conference">International Conference on Control, Automation and Systems 2018</span>
                    </td>
                </tr>
                <tr class="tr-pub-main">
                    <td class="tb-td-left">
                        <div class="img-placeholder-with-logo">
                            <img src="src/logo/snu.png" alt="Seoul National University" class="placeholder-logo">
                        </div>
                    </td>
                    <td class="tb-td-right">
                        <span class="paper-title">Wearable Cutaneous Haptic Interface with Soft Sensors and IMUs</span>
                        Yongjun Lee, Myungsin Kim, Yongseok Lee, <span class="my-author">Hyojoon Park</span>, and
                        Dongjun Lee
                        <br>
                        <span class="conference">Korea Robotics Society Annual Conference 2018</span>
                        <br>
                    </td>
                </tr>
</tr>
</tbody>
</table>
</td>
</tr>